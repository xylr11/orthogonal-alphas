{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c59599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sf_quant as sf\n",
    "import polars as pl\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0703495",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = dt.date(1996, 1, 1)\n",
    "end = dt.date(2024, 12, 31)\n",
    "\n",
    "columns = [\n",
    "    'date',\n",
    "    'barrid',\n",
    "    'price',\n",
    "    'return',\n",
    "    'specific_return',\n",
    "]\n",
    "\n",
    "df = pl.read_parquet(\"russell_3000_daily.parquet\")\n",
    "\n",
    "df.write_parquet(\"russell_3000_daily.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e257f18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA97X1\n",
      "shape: (632, 2)\n",
      "┌────────────┬─────────┐\n",
      "│ date       ┆ return  │\n",
      "│ ---        ┆ ---     │\n",
      "│ date       ┆ f64     │\n",
      "╞════════════╪═════════╡\n",
      "│ 2015-06-30 ┆ -1.1917 │\n",
      "│ 2015-07-01 ┆ 3.4171  │\n",
      "│ 2015-07-02 ┆ -0.3887 │\n",
      "│ 2015-07-06 ┆ 2.0488  │\n",
      "│ 2015-07-07 ┆ 0.956   │\n",
      "│ …          ┆ …       │\n",
      "│ 2017-12-22 ┆ -0.9314 │\n",
      "│ 2017-12-26 ┆ 0.5443  │\n",
      "│ 2017-12-27 ┆ 0.5413  │\n",
      "│ 2017-12-28 ┆ 0.2447  │\n",
      "│ 2017-12-29 ┆ -1.123  │\n",
      "└────────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "#Helper program to find stocks that have returns over the whole range of dates. I need to simulate the signals somehow.\n",
    "\n",
    "startDate = dt.date(2013, 1, 1) \n",
    "endDate = dt.date(2018, 1, 1)\n",
    "\n",
    "unique_barrids = df.filter(\n",
    "    pl.col(\"date\").is_between(startDate, endDate)\n",
    ").select(pl.col(\"barrid\")).unique()\n",
    "\n",
    "barrid = unique_barrids.sample(1)[0, 0]\n",
    "print(barrid)\n",
    "\n",
    "print(df.filter(\n",
    "    pl.col(\"date\").is_between(startDate, endDate),\n",
    "    (pl.col(\"barrid\") == barrid),\n",
    ").select(\n",
    "    pl.col(\"date\").alias(\"date\"),\n",
    "    pl.col(\"return\").alias(\"return\")\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce1b788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_259, 4)\n",
      "┌────────────┬───────────┬───────────┬───────────┐\n",
      "│ date       ┆ returns1  ┆ returns2  ┆ returns3  │\n",
      "│ ---        ┆ ---       ┆ ---       ┆ ---       │\n",
      "│ date       ┆ f64       ┆ f64       ┆ f64       │\n",
      "╞════════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 2013-01-02 ┆ 0.005376  ┆ 0.022719  ┆ 0.014524  │\n",
      "│ 2013-01-03 ┆ 0.032086  ┆ -0.008599 ┆ -0.003937 │\n",
      "│ 2013-01-04 ┆ 0.036269  ┆ 0.010481  ┆ -0.017248 │\n",
      "│ 2013-01-07 ┆ -0.0002   ┆ 0.010372  ┆ 0.001097  │\n",
      "│ 2013-01-08 ┆ -0.002801 ┆ 0.007788  ┆ 0.011687  │\n",
      "│ …          ┆ …         ┆ …         ┆ …         │\n",
      "│ 2017-12-22 ┆ -0.033333 ┆ 0.000254  ┆ 0.007785  │\n",
      "│ 2017-12-26 ┆ 0.0       ┆ 0.002284  ┆ 0.002107  │\n",
      "│ 2017-12-27 ┆ 0.0       ┆ -0.000506 ┆ -0.001402 │\n",
      "│ 2017-12-28 ┆ -0.002463 ┆ -0.003799 ┆ 0.009123  │\n",
      "│ 2017-12-29 ┆ -0.001235 ┆ -0.005594 ┆ 0.004172  │\n",
      "└────────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "barrid1 = \"USAQ392\"\n",
    "barrid2 = \"USAZ6Q1\"\n",
    "barrid3 = \"USAROU1\"\n",
    "\n",
    "\n",
    "training_data = df.filter(\n",
    "    pl.col(\"date\").is_between(startDate, endDate),\n",
    "    (pl.col(\"barrid\") == barrid1) | (pl.col(\"barrid\") == barrid2) | (pl.col(\"barrid\") == barrid3)\n",
    ").pivot(\"barrid\", index=\"date\", values=\"return\").select(\n",
    "    pl.col(\"date\"),\n",
    "    (pl.col(barrid1)/100).alias(\"returns1\"),\n",
    "    (pl.col(barrid2)/100).alias(\"returns2\"),\n",
    "    (pl.col(barrid3)/100).alias(\"returns3\")\n",
    ")\n",
    "\n",
    "print(training_data)\n",
    "\n",
    "#cum_returns = trainingdata.select(pl.col(\"date\"), np.log(pl.col(\"return\") + 1).cum_sum().alias(\"cumulative_returns\"))\n",
    "\n",
    "#print(cum_returns.select(pl.col(\"date\"), (np.exp(pl.col(\"cumulative_returns\"))-1).alias(\"Cumulative_Returns\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "142bf693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_error(cov_est, cov_real, exp_returns):\n",
    "    # cov_est and cov_true are 3x3 lists, mu is vector\n",
    "    #cov_est = np.array(cov_est, dtype=float)\n",
    "    #cov_real = np.array(cov_real, dtype=float)\n",
    "    #exp_returns = np.array(exp_returns, dtype=float)\n",
    "    if (np.linalg.det(cov_est) == 0): return 0\n",
    "    if (np.linalg.det(cov_real) == 0): return 0\n",
    "\n",
    "    x_est = np.linalg.solve(cov_est, exp_returns)\n",
    "    x_real = np.linalg.solve(cov_real, exp_returns)\n",
    "    return np.linalg.norm((x_est / np.sum(x_est)) - (x_real / np.sum(x_real)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd27fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cov_est_error(r, b): #ratio for geometric weighting.\n",
    "    error = 0.01 #approximately the contribution of the last day included in the average.\n",
    "    \n",
    "    num_r = int(np.floor_divide(np.log(error), np.log(r))) #num_rber of days computed in the average.\n",
    "    weights_r = [(r**i) for i in range(1, num_r + 1)] #weights_r for the rolling sum. Note they are automatially normalized.\n",
    "    \n",
    "    num_b = int(np.floor_divide(np.log(error), np.log(b))) #num_rber of days computed in the average.\n",
    "    weights_b = [(b**i) for i in range(1, num_b + 1)] #weights_r for the rolling sum. Note they are automatially normalized.\n",
    "\n",
    "    exprs_cov_construction = [pl.col(\"date\").alias(\"date\")] #Expressions for constructing columns representing covariance matrix coefficients.\n",
    "    for i in range(1, 4):\n",
    "        for j in range(1, 4):\n",
    "            exprs_cov_construction.append(\n",
    "                ((pl.col(f\"returns{i}\") - pl.col(f\"mu{i}\")) *\n",
    "                (pl.col(f\"returns{j}\") - pl.col(f\"mu{j}\"))).alias(f\"cov{i}{j}\")\n",
    "            )\n",
    "\n",
    "    exprs_cov_est = [] #Expressions for constructing estimated covariance matrix coefficients.\n",
    "    for i in range(1, 4):\n",
    "        for j in range(1, 4):\n",
    "            exprs_cov_est.append(\n",
    "                pl.col(f\"cov{i}{j}\").rolling_mean(num_r, weights_r).fill_null(strategy=\"backward\").alias(f\"cov_est{i}{j}\")\n",
    "            )\n",
    "    \n",
    "    exprs_cov_next = []\n",
    "    for i in range(1, 4):\n",
    "        for j in range(1, 4):\n",
    "            exprs_cov_next.append(\n",
    "                (pl.col(f\"cov{i}{j}\").shift(-1)).fill_null(strategy=\"forward\").alias(f\"cov_next{i}{j}\")\n",
    "            )\n",
    "\n",
    "    cov_data = training_data.with_columns(\n",
    "        pl.col(\"returns1\").rolling_mean(num_b, weights_b).fill_null(strategy=\"backward\").alias(\"mu1\"),\n",
    "        pl.col(\"returns2\").rolling_mean(num_b, weights_b).fill_null(strategy=\"backward\").alias(\"mu2\"),\n",
    "        pl.col(\"returns3\").rolling_mean(num_b, weights_b).fill_null(strategy=\"backward\").alias(\"mu3\")\n",
    "    ).with_columns( #Need the mu's to compute the covariance matrices.\n",
    "        exprs_cov_construction\n",
    "    ).with_columns( #Need the covariance matrix coefficients to compute the estimated future covariance matrix.\n",
    "        exprs_cov_est\n",
    "    ).with_columns(\n",
    "        exprs_cov_next\n",
    "    ).filter(\n",
    "        pl.col(\"date\").is_between(startDate + dt.timedelta(num_r + num_b), endDate)\n",
    "        #rolling_mean introduces a null in a row when there are too many weights_r for the num_rber of available elements. \n",
    "        #this is just filtering out backfilled nulls from two rolling_mean steps.\n",
    "    )\n",
    "\n",
    "    #print(cov_data.select(pl.col(\"cov_next11\"))) #USE THIS TO SEE NULL WHEN EXPRS_COV_NEXT HAS NO FORWARD FILL\n",
    "\n",
    "    cov_est_error = cov_data.select(\n",
    "        pl.struct([(f\"cov_est{i}{j}\") for i in range(1, 4) for j in range(1, 4)] + [(f\"cov_next{i}{j}\") for i in range(1, 4) for j in range(1, 4)] + [(f\"mu{i}\") for i in range(1, 4)]).map_elements(\n",
    "            lambda row: cov_error(np.array([[row[f\"cov_est{i}{j}\"] for i in range(1, 4)] for j in range(1, 4)]), np.array([[row[f\"cov_next{i}{j}\"] for i in range(1, 4)] for j in range(1, 4)]), np.array([row[f\"mu{i}\"] for i in range(1, 4)])),\n",
    "            return_dtype=pl.Float64\n",
    "        ).alias(\"cov_est_error\")\n",
    "    )\n",
    "    \n",
    "\n",
    "    return cov_est_error.select(pl.mean(\"cov_est_error\"))[0, 0]\n",
    "\n",
    "\n",
    "#np.linalg.solve(np.array([[pl.col(f\"est_cov{i}{j}\") for i in range(1, 4)] for j in range(1, 4)]), np.array([pl.col(f\"exp_returns{i}\") for i in range(1, 4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "11433422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cov Error: 16.662558998429976\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cov Error: {cov_est_error(0.95, 0.9)}\")\n",
    "\n",
    "#GET RID OF FILL_NULL IN EXPRS_COV_NEXT!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a406977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233 : 1.900957626132612\n"
     ]
    }
   ],
   "source": [
    "cov_errors = np.array([[cov_est_error(i/100.0, j/100.0) for j in range(70, 90)] for i in range(70, 90)])\n",
    "min_args = np.argmin(cov_errors)\n",
    "print(f\"{min_args} : {np.min(cov_errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dadb9cd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 233 is out of bounds for axis 0 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m reader = np.array([[[i/\u001b[32m100.0\u001b[39m, j/\u001b[32m100.0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[32m70\u001b[39m, \u001b[32m90\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m70\u001b[39m, \u001b[32m90\u001b[39m)])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mreader\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmin_args\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mIndexError\u001b[39m: index 233 is out of bounds for axis 0 with size 20"
     ]
    }
   ],
   "source": [
    "reader = np.array([[[i/100.0, j/100.0] for j in range (70, 90)] for i in range(70, 90)])\n",
    "print(reader[min_args])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orthogonal-alphas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
